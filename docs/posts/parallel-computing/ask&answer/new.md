# FlashAttention 在昇腾 NPU 上的两种实现方案对比分析报告

## 1. 背景与问题定义

本报告对比分析了在华为昇腾 NPU 上实现 FlashAttention 算法的两种方案。目标是对规模为 Q, K, V ∈ ℝ^(8192×128) 的注意力机制进行高效计算。

### 1.1 硬件架构
- **计算单元**：1 个 Cube（矩阵乘法单元）+ 2 个 Vec Kernel（向量计算单元）
- **存储层次**：
  - L1：片上高速缓存
  - L2：192 MB 共享缓存（10 组 Cube+Vec 共享）
  - HBM：主存储器

### 1.2 分块策略
- **基本块大小**：16×16 元素
- **矩阵分块**：
  - Q: 8192×128 → 512×8 个小块（记为 Q_{i,j}，i∈[1,512], j∈[1,8]）
  - K: 8192×128 → 512×8 个小块（记为 K_{i,j}）
  - V: 8192×128 → 512×8 个小块（记为 V_{i,j}）
  
- **最小计算单元**：16×16×16 矩阵乘法（一次 Cube 操作）

### 1.3 数据类型
- **输入矩阵 Q, K, V**：FP16 (2 bytes/元素)
- **QK^T 结果**：FP16 (2 bytes/元素)
- **Softmax 计算与中间结果**：FP32 (4 bytes/元素)
- **最终输出**：FP16 (2 bytes/元素)

---

## 2. 做法 A：分行全计算方案（无 Online Softmax）

### 2.1 核心思想
一次性计算完整的 QK^T 行（16×8192），完成整行 Softmax 后再与 V 相乘。每次处理 16 行作为一组，共需 512 组完成全部 8192 行。

### 2.2 详细流程（处理第 i 组，即第 16(i-1)+1 到 16i 行）

#### **Stage 1: 计算完整的 QK^T 行**
**目标**：计算 QK^T 的第 16(i-1)+1 到 16i 行（完整的 16×8192 矩阵）

**计算过程**：
```
For j = 1 to 512:          // 遍历 K 的所有行块
    For k = 1 to 8:        // 遍历列维度
        Cube 执行: Q_{i,k} @ K_{j,k}^T  (16×16 矩阵乘)
    累加 8 个乘积得到 QK^T_{i,j} (16×16 小块)
End
```

**计算量**：
- 矩阵乘次数：512 × 8 = **4,096 次**
- 输出：16×8192 的 QK^T 矩阵（FP16）

**L2 操作**：
- **写 L2**：16×8192 元素 × 2 bytes = **256 KB**（1 次大块写）

---

#### **Stage 2: 计算 Softmax**
**目标**：对 16 行分别计算长度为 8192 的 Softmax

**计算过程**：
```
For row = 1 to 16:
    vec_id = (row - 1) / 8          // Vec 0 处理前 8 行，Vec 1 处理后 8 行
    Vec[vec_id] 从 L2 读取该行 8192 个 FP16 元素
    转换为 FP32 并计算 Softmax(8192)
    将结果（FP32）写回 L2
End
```

**计算量**：
- Softmax 计算：16 次，每次长度 8192（FP32）
- Vec 轮数：8 轮（每个 Vec 每轮处理 1 行）

**L2 操作**：
- **读 L2**：16×8192 元素 × 2 bytes = **256 KB**（读 FP16）
- **写 L2**：16×8192 元素 × 4 bytes = **512 KB**（写 FP32）（1 次大块写）

---

#### **Stage 3: 计算 Softmax(QK^T) @ V**
**目标**：计算注意力输出的 16 行（16×128）

**计算过程**：
```
For j = 1 to 8:            // 遍历 V 的列块
    For k = 1 to 512:      // 遍历 V 的行块
        Cube 执行: Softmax_{i,k} @ V_{k,j}  (16×16 矩阵乘)
    累加 512 个乘积得到 Output_{i,j} (16×16 小块)
End
```

**计算量**：
- 矩阵乘次数：8 × 512 = **4,096 次**

**L2 操作**：
- **读 L2**：16×8192 元素 × 4 bytes = **512 KB**（读 FP32 的 Softmax 结果）
- **写 L2**：16×128 元素 × 2 bytes = **4 KB**（写 FP16 的最终输出）（1 次小块写）

---

### 2.3 总体性能指标（处理 16 行）

| 指标 | 数值 |
|------|------|
| Cube 矩阵乘次数 | 8,192 次 |
| Vec Softmax 计算 | 16 次 × 8192 长度 (FP32) |
| Vec 计算轮数 | 8 轮 |
| **L2 总写入量** | 256 + 512 + 4 = **772 KB** |
| **L2 总读取量** | 256 + 512 = **768 KB** |
| **L2 总传输量** | **1,540 KB** |
| **L2 写操作次数** | **3 次** |
| L2 峰值占用 | ~772 KB |

### 2.4 完成全部 8192 行
- 外层循环：512 组
- 总矩阵乘：512 × 8,192 = **4,194,304 次**
- 总 Softmax：8,192 行
- 总 L2 传输：512 × 1.54 MB ≈ **788 MB**

---

## 3. 做法 B：FlashAttention 风格方案（Online Softmax）

### 3.1 核心思想
不一次性计算完整行的 QK^T，而是分 16 轮，每轮计算一个 16×512 的"条带"，使用 Online Softmax 算法逐步更新统计量（max 和 sum），最终得到完整的注意力输出。

### 3.2 详细流程（处理第 i 组的 16 行，共 16 轮迭代）

#### **第 t 轮（t = 1 to 16）**

---

#### **Stage 1: 计算部分 QK^T**
**目标**：计算 QK^T 的第 (t-1)×32+1 到 t×32 列块（16×512 条带）

**计算过程**：
```
For j = (t-1)×32+1 to t×32:    // 当前轮的 32 个列块
    For k = 1 to 8:             // 遍历列维度
        Cube 执行: Q_{i,k} @ K_{j,k}^T  (16×16 矩阵乘)
    累加得到 QK^T_{i,j} (16×16 小块)
End
```

**计算量**：
- 矩阵乘次数：32 × 8 = **256 次**

**L2 操作**：
- **写 L2**：16×512 元素 × 2 bytes = **16 KB**（FP16）

---

#### **Stage 2: 计算局部 Softmax**
**目标**：对当前 16×512 条带计算局部 Softmax 统计量

**计算过程**：
```
For row = 1 to 16:
    Vec 从 L2 读取该行的 512 个 FP16 元素
    转换为 FP32
    计算局部统计量:
        row_max_t = max(512 个元素)
        row_sum_t = Σ exp(x - row_max_t)
    存储 exp(x - row_max_t) 结果（FP32）到 L2
End
```

**计算量**：
- Softmax 计算：16 次，每次长度 512（FP32）

**L2 操作**：
- **读 L2**：16×512 元素 × 2 bytes = **16 KB**（读 FP16）
- **写 L2**：16×512 元素 × 4 bytes = **32 KB**（写 FP32）

---

#### **Stage 3: 计算部分 Attention @ V**
**目标**：计算当前条带对最终输出的贡献

**计算过程**：
```
For j = 1 to 8:                 // 遍历 V 的列块
    For k = (t-1)×32+1 to t×32: // 当前轮的 32 个行块
        Cube 执行: Softmax_{i,k} @ V_{k,j}  (16×16 矩阵乘)
    累加得到部分输出 PartialOutput_{i,j}^t (16×16 小块)
End
```

**计算量**：
- 矩阵乘次数：8 × 32 = **256 次**

**L2 操作**：
- **读 L2**：16×512 元素 × 4 bytes = **32 KB**（读 FP32 的局部 Softmax）
- **读 L2**（t > 1）：16×128 元素 × 2 bytes = **4 KB**（读旧的累积输出）
- **写 L2**：16×128 元素 × 2 bytes = **4 KB**（写更新后的累积输出）

---

#### **Stage 4: Online Softmax 更新（Rescaling）**
**目标**：合并当前轮与之前轮次的统计量

**更新公式**：
```
For row = 1 to 16:
    new_max = max(old_max, current_max_t)
    
    old_scale = exp(old_max - new_max)
    current_scale = exp(current_max_t - new_max)
    
    new_sum = old_sum × old_scale + current_sum_t × current_scale
    
    new_output = (old_output × old_scale × old_sum + 
                  current_output × current_scale × current_sum_t) / new_sum
    
    更新全局统计量: old_max ← new_max, old_sum ← new_sum
End
```

**说明**：
- 第 1 轮不需要 Rescaling
- 第 2-16 轮需要执行 Rescaling
- Rescaling 涉及的读写已包含在 Stage 3 中

---

### 3.3 单轮性能指标

| 指标 | 数值 |
|------|------|
| Cube 矩阵乘次数 | 256 + 256 = 512 次 |
| Vec Softmax 计算 | 16 次 × 512 长度 (FP32) |
| **L2 单轮写入量** | 16 + 32 + 4 = **52 KB** |
| **L2 单轮读取量** | 16 + 32 + 4 = **52 KB** |
| **L2 单轮传输量** | **104 KB** |
| **L2 单轮写操作次数** | **4 次** |
| L2 峰值占用 | ~52 KB |

### 3.4 16 轮总计（处理 16 行）

| 指标 | 数值 |
|------|------|
| Cube 矩阵乘次数 | 16 × 512 = **8,192 次** |
| Vec Softmax 计算 | 256 次 × 512 长度 (FP32) |
| Rescaling 次数 | 15 次 |
| **L2 总写入量** | 16 × 52 = **832 KB** |
| **L2 总读取量** | 16 × 52 = **832 KB** |
| **L2 总传输量** | **1,664 KB** |
| **L2 写操作次数** | **64 次** (16 轮 × 4 次/轮) |
| L2 峰值占用 | ~52 KB |

### 3.5 完成全部 8192 行
- 外层循环：512 组
- 总矩阵乘：512 × 8,192 = **4,194,304 次**
- 总 Softmax：512 × 256 = **131,072 次** × 512 长度
- 总 L2 传输：512 × 1.664 MB ≈ **852 MB**

---

## 4. 两种方案对比

### 4.1 总体对比表（处理 16 行）

| 指标 | 做法 A | 做法 B | 差异 |
|------|--------|--------|------|
| **Cube 矩阵乘次数** | 8,192 | 8,192 | 相同 |
| **Vec Softmax 计算** | 16 次 × 8192 长度 | 256 次 × 512 长度 | 不同 |
| **L2 总传输量** | 1,540 KB | 1,664 KB | A 少 8% |
| **L2 写入量** | 772 KB | 832 KB | A 少 7% |
| **L2 写操作次数** | **3 次** | **64 次** | **A 少 95%** |
| **单次写大小** | 大 (256/512 KB) | 小 (16/32/4 KB) | A 更大 |
| **L2 峰值占用** | ~772 KB | ~52 KB | B 少 93% |
| **Rescaling 开销** | 无 | 15 次 | A 更简单 |

### 4.2 关键差异分析

#### **计算端**
- **矩阵乘法**：两种方案完全相同，均为 8,192 次
- **Softmax 计算**：
  - 做法 A：16 次长 Softmax（8192 长度，FP32）
  - 做法 B：256 次短 Softmax（512 长度，FP32）
  - **影响因素**：Vec 单元处理不同长度的效率差异

#### **内存端**
- **L2 传输总量**：做法 A 少 8%（1.54 MB vs 1.66 MB）
- **L2 写次数**：做法 A **少 95%**（3 次 vs 64 次）
- **L2 峰值占用**：做法 B 少 93%（52 KB vs 772 KB）

---

## 5. 关键假设与性能预测

### 5.1 核心假设

**假设 1：L2 写操作存在固定延迟**

L2 写操作的时间模型：
```
T_write = N × L_fixed + Data / B_L2
```

其中：
- `N`：写操作次数
- `L_fixed`：每次写的固定延迟（包括写缓冲刷新、缓存一致性协议开销等）
- `Data`：总写入数据量
- `B_L2`：L2 写带宽

---

### 5.2 性能预测场景

#### **场景 1：带宽受限（L_fixed ≈ 0）**

**条件**：固定延迟可忽略，性能完全由带宽决定

**写时间对比**：
```
做法 A: T_A = 772 KB / B_L2
做法 B: T_B = 832 KB / B_L2

速度比: T_B / T_A ≈ 1.08
```

**结论**：做法 A 快约 **8%**

---

#### **场景 2：存在显著固定延迟**

**假设**：L_fixed = 100 ns，B_L2 = 500 GB/s

**写时间对比**：
```
做法 A: T_A = 3 × 100 ns + 772 KB / (500 GB/s)
         = 300 ns + 1.54 μs = 1.84 μs

做法 B: T_B = 64 × 100 ns + 832 KB / (500 GB/s)
         = 6,400 ns + 1.66 μs = 8.06 μs

速度比: T_B / T_A ≈ 4.4
```

**结论**：做法 A 快约 **4.4 倍**

---

#### **场景 3：固定延迟主导**

**假设**：L_fixed = 500 ns（较高的缓存一致性开销）

**写时间对比**：
```
做法 A: T_A = 3 × 500 ns + 1.54 μs = 3.04 μs
做法 B: T_B = 64 × 500 ns + 1.66 μs = 33.66 μs

速度比: T_B / T_A ≈ 11
```

**结论**：做法 A 快约 **11 倍**

---

### 5.3 判断标准

定义 **延迟主导因子** α：

```
α = (L_fixed × ΔN) / (Data / B_L2)
  = (L_fixed × 61) / (772 KB / B_L2)
```

其中 ΔN = 64 - 3 = 61（写次数差）

**性能预测**：
- **α << 1**（α < 0.5）：带宽受限，做法 A 仅快 ~8%
- **α ≈ 1**（0.5 < α < 2）：混合瓶颈，做法 A 快 2-5 倍
- **α >> 1**（α > 2）：延迟受限，做法 A 快 5-10+ 倍

---

### 5.4 其他性能因素

#### **因素 1：Softmax 计算效率**

**做法 A**：
- 16 次 × 8192 长度
- Vec 单元可能需要分批处理（如果寄存器不足）

**做法 B**：
- 256 次 × 512 长度
- 每次计算更小，可能有更好的局部性和寄存器利用率

**影响**：如果 Vec 处理短向量更高效，做法 B 可能在计算端有优势

---

#### **因素 2：流水并行潜力**

**做法 A**：
- Stage 1 → Stage 2 → Stage 3 顺序执行
- Cube 和 Vec 难以同时工作

**做法 B**：
- 16 轮迭代，可能实现跨轮次的流水
- 例如：第 t 轮的 Cube 计算 与 第 t-1 轮的 Vec Softmax 并行

**影响**：如果能有效流水，做法 B 可能提升整体吞吐

---

#### **因素 3：多行并行**

如果同时处理 M 组（M × 16 行）：

**L2 占用**：
- 做法 A：M × 772 KB
- 做法 B：M × 52 KB

**影响**：
- 做法 B 可以支持更高的并行度（如 M = 10 时，占用仅 520 KB vs 7.72 MB）
- 更高并行度可能带来更好的硬件利用率

---

## 6. 测试方案

### 6.1 测试目标

1. **确定 L2 写操作的固定延迟** L_fixed
2. **测量 L2 有效带宽** B_L2
3. **对比不同长度 Softmax 的计算效率**
4. **对比两种方案的端到端性能**

---

### 6.2 测试 1：L2 写延迟与带宽测试

#### **测试 A：大块写**
```python
# 模拟做法 A 的写模式
for iteration in range(N_iterations):
    write_L2(buffer_256KB)   # 第 1 次写
    write_L2(buffer_512KB)   # 第 2 次写
    write_L2(buffer_4KB)     # 第 3 次写
    barrier()
    
measure_time()
```

#### **测试 B：小块写**
```python
# 模拟做法 B 的写模式
for iteration in range(N_iterations):
    for round in range(16):
        write_L2(buffer_16KB)   # Stage 1
        write_L2(buffer_32KB)   # Stage 2
        write_L2(buffer_4KB)    # Stage 3 (1)
        write_L2(buffer_4KB)    # Stage 3 (2)
    barrier()
    
measure_time()
```

#### **分析方法**
假设测试 A 用时 T_A，测试 B 用时 T_B

理论模型：
```
T_A = N × (3 × L_fixed + 772 KB / B_L2)
T_B = N × (64 × L_fixed + 832 KB / B_L2)
```

通过测量不同 N 下的时间，拟合出 L_fixed 和 B_L2

---

### 6.3 测试 2：Softmax 计算效率对比

#### **测试 A：长 Softmax**
```python
# Vec Kernel 测试
for i in range(1000):
    softmax_fp32_length_8192()
    
measure_time()
```

#### **测试 B：短 Softmax**
```python
# Vec Kernel 测试
for i in range(16000):  # 16000 次以匹配总元素数
    softmax_fp32_length_512()
    
measure_time()
```

#### **指标**
- 每个元素的平均处理时间
- Vec 单元利用率
- 是否受启动开销影响

---

### 6.4 测试 3：端到端性能对比

#### **实现要点**
- 完整实现做法 A 和做法 B
- 处理相同规模的输入（如 16 行）
- 测量总时间、各阶段时间、L2 传输时间

#### **性能分解**
```
总时间 = Cube 计算时间 + Vec 计算时间 + L2 传输时间 + 其他开销

分析各部分占比，确定瓶颈
```

#### **Profiling 工具**
使用昇腾 NPU 的性能分析工具（如 MindSpore Profiler 或 CANN Profiler）：
- L2 读写带宽利用率
- Cube 和 Vec 的计算利用率
- 各操作的时间分布

---

### 6.5 测试 4：不同并行度下的性能

#### **测试方案**
同时处理不同数量的行组（M = 1, 2, 4, 8）

**关注指标**：
- L2 容量是否成为限制
- 是否出现带宽饱和
- 整体吞吐的扩展性

---

## 7. 预期结论

### 7.1 如果 L2 写存在显著固定延迟（L_fixed > 50 ns）

**预期结果**：
- 做法 A 在 L2 写性能上有 **2-10 倍优势**
- 整体性能做法 A 可能快 **1.5-5 倍**（取决于计算是否也是瓶颈）

**适用场景**：
- 单行或少量行的处理
- L2 写延迟较高的硬件
- 对延迟敏感的应用

---

### 7.2 如果 L2 写主要受带宽限制（L_fixed ≈ 0）

**预期结果**：
- 做法 A 仅快 **~8%**（传输量略少）
- 如果 Vec 处理短 Softmax 更高效，做法 B 可能持平或略快

**适用场景**：
- L2 带宽充足
- 写延迟极低的硬件

---

### 7.3 如果需要高并行度

**预期结果**：
- 做法 B 由于 L2 占用小（52 KB vs 772 KB），可支持更多行并行
- 在多行并行时，做法 B 可能有 **更高的整体吞吐**

**适用场景**：
- 批处理大量数据
- 追求整体吞吐而非单次延迟

---

## 8. 建议

### 8.1 立即执行
1. **运行测试 1**，确定 L2 写的固定延迟 L_fixed
2. **运行测试 2**，对比 Softmax 计算效率
3. 根据测试结果决定主推方案

### 8.2 深入分析
- 使用 Profiler 详细分析端到端性能
- 研究是否可以结合两种方案的优点（如混合分块策略）
- 探索 Cube-Vec 流水并行的可能性

### 8.3 长期优化
- 考虑做法 B 的变体：调整条带大小（如 16×1024 而非 16×512）
- 研究更激进的并行策略（如同时处理多组 16 行）
- 探索硬件特性（如 DMA、预取）的优化空间

---

## 9. 总结

本报告详细对比了两种 FlashAttention 实现方案：

- **做法 A（分行全计算）**：简单直接，L2 写次数极少（3 次），但峰值占用较高
- **做法 B（Online Softmax）**：内存友好，支持高并行，但 L2 写次数多（64 次）

**核心判断依据**：L2 写操作的固定延迟

- **如果固定延迟显著**：做法 A 可能快 2-10 倍
- **如果固定延迟很小**：两者性能接近，做法 B 在并行场景可能更优

**推荐测试方案**：
1. L2 写延迟/带宽测试
2. Softmax 长度效率对比
3. 端到端性能对比

通过系统的测试，可以量化关键参数，做出数据驱动的方案选择。