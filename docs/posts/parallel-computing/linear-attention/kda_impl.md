# KDA Chunkwise 算法在昇腾 NPU 上的实现方案

## 1. 硬件约束总结

| 组件 | 能力 | 说明 |
|------|------|------|
| **Cube Kernel** | 128×128 矩阵乘 | 输入 512×128 左矩阵 + 128×512 右矩阵，**只能做 matmul** |
| **Vec Kernel** | 8192 元素并行 | 1 Cube 对应 2 Vec，**负责所有逐元素操作** |
| **L2 Buffer** | 20 组共享 | Cube ↔ Vec 通信必经之路 |

### ⚠️ 关键约束

```
Cube Kernel: 只能做矩阵乘法 (A @ B)
Vec Kernel:  负责所有逐元素操作 (⊙, +, -, exp, mask, etc.)

所有 ⊙ 操作必须: Cube 输出 → L2 → Vec 处理 → L2 → Cube 继续
```

---

## 2. KDA 计算任务分解

回顾 KDA 的核心计算：

```
输入: Q, K, V ∈ R^{C×d}  (C=chunk_size, d=128)
     α ∈ [0,1]^{C×d} (细粒度衰减门)
     β ∈ [0,1]^C (学习率)
     S ∈ R^{d×d} (状态矩阵, 128×128)

核心计算:
1. A_kk = (K ⊙ Γ) @ (K/Γ)^T        -- Cube: C×d @ d×C → C×C
2. M = (I + StrictTril(A_kk))^{-1}  -- Vec: 前向替换
3. W = M @ (Γ ⊙ K)                  -- Cube: C×C @ C×d → C×d  
4. U = M @ V                        -- Cube: C×C @ C×d → C×d
5. A_qk = (Q ⊙ Γ) @ (K/Γ)^T        -- Cube: C×d @ d×C → C×C
6. O = (Q ⊙ Γ) @ S + Tril(A_qk) @ (U - W@S)  -- Cube + Vec
7. S_new = decay(S) + K^T @ (U - W@S)        -- Cube + Vec
```

### 2.1 累积衰减 Γ 的计算

论文定义（第3页）：

$$\gamma_{[t]}^{i \to j} := \prod_{k=i}^{j} \alpha_{[t]}^k \quad \text{(累积乘积)}$$

简写：$\gamma_{[t]}^r := \gamma_{[t]}^{1 \to r}$

**问题**：直接连乘 $\alpha \in [0,1]$ 会导致数值下溢（接近0）

**解决**：在 log 域计算

$$\log(\gamma^{1 \to r}) = \sum_{k=1}^{r} \log(\alpha^k)$$

```python
# 实际实现
log_alpha = log(alpha)              # α ∈ [0,1] → log(α) ≤ 0
gc = cumsum(log_alpha, dim=0)       # gc[r] = Σ_{k=1}^r log(α_k)
Gamma = exp(gc)                     # Γ[r] = γ^{1→r} = ∏_{k=1}^r α_k
```

**Γ 矩阵的含义**：
- `Γ[r, d]` = 从位置 1 到位置 r，第 d 维的累积衰减
- 用于将相对位置关系编码到注意力计算中

---

## 3. 参数选择与分块策略

### 3.1 推荐配置

```
d_k = d_v = 128          # head dimension (匹配 Cube 128×128)
chunk_size C = 64        # 原论文推荐
mini_chunk = 4           # 二级分块，用于数值稳定性
```

### 3.2 矩阵尺寸映射

| 矩阵 | 尺寸 | Cube Tile 策略 |
|------|------|----------------|
| K, Q, V | 64×128 | 1 tile (< 512×128) |
| S | 128×128 | 1 tile (128×128) |
| A_kk, A_qk | 64×64 | 1 tile (< 128×128) |
| W, U | 64×128 | 1 tile |

---

## 4. 整体流程图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                         KDA Chunk 处理流程                               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌─────────────┐                                                        │
│  │ 输入: Q,K,V │                                                        │
│  │ g, β, S_prev│                                                        │
│  └──────┬──────┘                                                        │
│         │                                                               │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 1: 预处理 (Vec Kernel)                                      │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ # 论文定义: γ^{1→r} = ∏_{k=1}^{r} α^k (累积乘积)            │   │   │
│  │ │ # 为避免数值下溢，在 log 域计算:                            │   │   │
│  │ │ #   log(γ^{1→r}) = Σ_{k=1}^{r} log(α^k)                    │   │   │
│  │ │                                                             │   │   │
│  │ │ • log_alpha = log(α)       # α 已经是 [0,1]，取 log 得负数  │   │   │
│  │ │ • gc = cumsum(log_alpha)   # gc[r] = Σ_{k=1}^{r} log(α^k)  │   │   │
│  │ │ • Γ = exp(gc)              # Γ[r] = γ^{1→r} = ∏_{k=1}^{r}α │   │   │
│  │ │                                                             │   │   │
│  │ │ • K_scaled = K ⊙ Γ         # K[r] * γ^{1→r}                │   │   │
│  │ │ • K_div = K / Γ = K ⊙ exp(-gc)  # K[r] / γ^{1→r}           │   │   │
│  │ │ • Q_scaled = Q ⊙ Γ         # Q[r] * γ^{1→r}                │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: K_scaled, K_div, Q_scaled → Cube                   │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 2: 注意力矩阵计算 (Cube Kernel)                             │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ A_kk_raw = K_scaled @ K_div^T  # 64×128 @ 128×64 → 64×64   │   │   │
│  │ │ # 注意: Cube 只做 matmul，不做逐元素操作                    │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: A_kk_raw → Vec                                     │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 3: 逐元素处理 + 矩阵求逆 (Vec Kernel)                       │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ # Step 1: 逐元素乘 β (Cube 不能做!)                         │   │   │
│  │ │ A_kk = A_kk_raw ⊙ β           # element-wise multiply      │   │   │
│  │ │                                                             │   │   │
│  │ │ # Step 2: 前向替换求逆                                      │   │   │
│  │ │ A = -StrictTril(A_kk)                                       │   │   │
│  │ │ for i in 1..C:                                              │   │   │
│  │ │     A[i,:i] += sum(A[i,j] * A[j,:i] for j in range(i))     │   │   │
│  │ │ M = (A + I) ⊙ β                                             │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: M → Cube                                           │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 4: 辅助矩阵计算 (Cube Kernel)                               │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ W = M @ K_scaled          # 64×64 @ 64×128 → 64×128        │   │   │
│  │ │ U = M @ V                 # 64×64 @ 64×128 → 64×128        │   │   │
│  │ │ WS = W @ S_prev           # 64×128 @ 128×128 → 64×128      │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: U, WS → Vec                                        │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 5: Pseudo-Value 计算 (Vec Kernel)                          │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ V_pseudo = U - WS          # 64×128, element-wise          │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: V_pseudo, Q_scaled → Cube                          │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 6: 输出计算 (Cube Kernel)                                   │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ # Inter-chunk: 历史信息                                     │   │   │
│  │ │ O_inter = Q_scaled @ S_prev    # 64×128 @ 128×128 → 64×128 │   │   │
│  │ │                                                             │   │   │
│  │ │ # Intra-chunk: 先算 raw attention                           │   │   │
│  │ │ A_qk_raw = Q_scaled @ K_div^T  # 64×128 @ 128×64 → 64×64   │   │   │
│  │ │ # 注意: Tril mask 是逐元素操作，需在 Vec 中完成!            │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: O_inter, A_qk_raw → Vec                            │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 6.5: Tril Mask (Vec Kernel)                                 │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ A_qk_tril = Tril(A_qk_raw)     # 逐元素 mask               │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: A_qk_tril → Cube                                   │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 6.6: Intra-chunk Matmul (Cube Kernel)                       │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ O_intra = A_qk_tril @ V_pseudo # 64×64 @ 64×128 → 64×128   │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: O_intra → Vec (与 O_inter 合并)                    │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 7: 输出融合 (Vec Kernel)                                    │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ O = O_inter + O_intra      # 64×128, element-wise add      │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: K_scaled (复用), V_pseudo → Cube                   │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 8: 状态更新 (Cube Kernel)                                   │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ # 需要 K^T @ V_pseudo，但 K 要带从 r 到 C 的衰减            │   │   │
│  │ │ # γ^{r→C} = γ^{1→C} / γ^{1→r} = exp(gc[C] - gc[r])         │   │   │
│  │ │ K_decay = K ⊙ exp(gc[-1] - gc)    # Vec 预处理 (Phase 7)   │   │   │
│  │ │ S_delta = K_decay^T @ V_pseudo  # 128×64 @ 64×128 → 128×128│   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         │ L2 Buffer: S_delta → Vec                                      │
│         ▼                                                               │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │ Phase 9: 状态融合 (Vec Kernel)                                    │   │
│  │ ┌────────────────────────────────────────────────────────────┐   │   │
│  │ │ # S_new = γ^{1→C} ⊙ S_prev + S_delta                       │   │   │
│  │ │ decay = exp(gc[-1])        # [128], chunk 整体衰减         │   │   │
│  │ │ S_new = S_prev ⊙ decay + S_delta  # 128×128 element-wise   │   │   │
│  │ └────────────────────────────────────────────────────────────┘   │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│         │                                                               │
│         ▼                                                               │
│  ┌─────────────┐                                                        │
│  │ 输出: O, S  │                                                        │
│  └─────────────┘                                                        │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 5. Cube-Vec 协作时序图

```
时间 →
     
Cube  ║▓▓▓▓▓▓▓▓▓▓║            ║▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓║      ║▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓║      ║▓▓▓▓▓▓▓▓▓▓║
      │ A_kk_raw │            │ W, U, WS         │      │O_inter,A_qk,O_intra│      │ S_delta  │
      │ (matmul) │            │ (3× matmul)      │      │ (3× matmul)        │      │ (matmul) │
      └────┬─────┘            └────────┬─────────┘      └──────────┬─────────┘      └────┬─────┘
           │                          │                           │                      │
    L2     ▼                          ▼                           ▼                      ▼
Buffer ═════════════════════════════════════════════════════════════════════════════════════════
           │                          │                           │                      │
Vec   ║▓▓▓▓▓▓▓▓▓▓▓▓║▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓║▓▓▓▓▓▓║         ║▓▓▓▓▓▓▓▓▓▓║         ║▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓║
      │ 预处理:     │A_kk⊙β + 前向替换│V_pseudo│         │ O融合    │         │ S融合 + 预处理 │
      │ Γ,K_sc,... │ → M (含逐元素!)  │        │         │(逐元素加)│         │ → 下一chunk   │
      └────────────┴─────────────────┴────────┘         └──────────┘         └────────────────┘

Phase:  1                2       3        4      5           6      7              8      9

注: Cube 只做 matmul, 所有 ⊙ (逐元素) 操作必须在 Vec 中完成!
```

---

## 6. L2 Buffer 分配策略

### 6.1 缓存需求分析

| 矩阵 | 尺寸 | 大小 (FP16) | 生命周期 |
|------|------|-------------|----------|
| K_scaled | 64×128 | 16 KB | Phase 1-8 |
| K_div | 64×128 | 16 KB | Phase 1-6 |
| Q_scaled | 64×128 | 16 KB | Phase 1-6 |
| V | 64×128 | 16 KB | Phase 4 |
| A_kk | 64×64 | 8 KB | Phase 2-3 |
| M | 64×64 | 8 KB | Phase 3-4 |
| W | 64×128 | 16 KB | Phase 4 |
| U | 64×128 | 16 KB | Phase 4-5 |
| V_pseudo | 64×128 | 16 KB | Phase 5-8 |
| S_prev | 128×128 | 32 KB | 常驻 |
| **峰值总计** | | **~160 KB** | |

### 6.2 分组策略 (20 组 Cube+Vec)

```
┌─────────────────────────────────────────────────────────────────┐
│                    L2 Buffer 分区 (假设 2MB 共享)                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐              │
│  │ 双缓冲区 A  │  │ 双缓冲区 B  │  │ 状态常驻区  │              │
│  │ (输入)      │  │ (输出)      │  │             │              │
│  │ ~80KB      │  │ ~80KB      │  │ S: 32KB     │              │
│  └─────────────┘  └─────────────┘  └─────────────┘              │
│                                                                 │
│  策略: Ping-Pong 双缓冲                                          │
│  - Cube 写入 Buffer A 时, Vec 读取 Buffer B                     │
│  - Cube 写入 Buffer B 时, Vec 读取 Buffer A                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 7. 多 Head 并行策略

对于多头注意力 (如 16 heads)，利用 20 组 Cube+Vec：

```
┌────────────────────────────────────────────────────────────┐
│                   16 Heads 分配到 20 组                     │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  Round 1: Group 0-15 各处理 1 个 head                      │
│  Group 16-19: 空闲 或 处理下一 chunk 的预处理               │
│                                                            │
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐     ┌─────┐ ┌─────┐       │
│  │ G0  │ │ G1  │ │ G2  │ │ G3  │ ... │ G15 │ │G16+ │       │
│  │ H0  │ │ H1  │ │ H2  │ │ H3  │     │ H15 │ │预取 │       │
│  └─────┘ └─────┘ └─────┘ └─────┘     └─────┘ └─────┘       │
│                                                            │
│  每组独立 L2 分区，无跨组通信                               │
│                                                            │
└────────────────────────────────────────────────────────────┘
```

---

## 8. 关键优化点

### 8.1 减少 Cube-Vec 通信

```python
# 优化前: 每次计算都 Cube → L2 → Vec → L2 → Cube
# 优化后: 合并计算，减少通信轮次

# Phase 4 合并: W, U, WS 在同一 Cube 阶段完成
# 避免 W 单独传回 Vec 再传 Cube
```

### 8.2 Tril 掩码处理

```python
# Cube 不能做逐元素操作!
# 必须拆分为: Cube(matmul) → Vec(tril mask) → Cube(matmul)

# 优化策略: 
# 1. 如果 A_qk 较小(64×64=4096)，Vec 处理 tril 很快
# 2. 可以与其他 Vec 操作合并，减少 L2 通信轮次
```

### 8.3 状态更新的延迟隐藏

```python
# 当 Cube 计算 S_delta 时
# Vec 可以并行处理下一 chunk 的 Phase 1 预处理
# 流水线隐藏延迟
```

---

## 9. 伪代码 (昇腾风格)

```python
def kda_chunk_ascend(Q, K, V, g, beta, S_prev):
    """
    单个 chunk 的 KDA 计算
    Q, K, V: [C, d] = [64, 128]
    g: [C, d] 衰减参数
    beta: [C] 学习率
    S_prev: [d, d] = [128, 128] 前一状态
    """
    
    # ========== Phase 1: Vec 预处理 ==========
    with Vec():
        # 论文定义: γ^{1→r} = ∏_{k=1}^{r} α^k
        # 在 log 域计算避免数值下溢:
        #   log(γ^{1→r}) = Σ log(α^k)
        
        log_alpha = log(alpha)            # alpha ∈ [0,1], log 得负数
        gc = cumsum(log_alpha, dim=0)     # gc[r] = Σ_{k=1}^r log(α^k)
        
        # Γ[r] = γ^{1→r} = exp(gc[r])
        Gamma = exp(gc)                   # [64, 128]
        Gamma_inv = exp(-gc)              # 1/Γ，用于 K_div
        
        K_scaled = K * Gamma              # K[r] * γ^{1→r}
        K_div = K * Gamma_inv             # K[r] / γ^{1→r}
        Q_scaled = Q * Gamma              # Q[r] * γ^{1→r}
    
    sync_to_L2(K_scaled, K_div, Q_scaled, V)
    
    # ========== Phase 2: Cube A_kk (只做 matmul!) ==========
    with Cube():
        A_kk_raw = matmul(K_scaled, K_div.T)  # [64, 64], 纯矩阵乘
    
    sync_to_L2(A_kk_raw)
    
    # ========== Phase 3: Vec 逐元素 + 前向替换 ==========
    with Vec():
        # Cube 不能做逐元素乘，必须在 Vec 中完成!
        A_kk = A_kk_raw * beta.unsqueeze(-1)  # [64, 64] ⊙ [64, 1]
        
        A_kk_masked = -strict_tril(A_kk)
        # 前向替换求逆
        for i in range(1, C):
            A_kk_masked[i, :i] += (A_kk_masked[i, :, None] * 
                                   A_kk_masked[:, :i]).sum(dim=0)
        M = (A_kk_masked + eye(C)) * beta.unsqueeze(-1)
    
    sync_to_L2(M)
    
    # ========== Phase 4: Cube W, U, WS ==========
    with Cube():
        W = matmul(M, K_scaled)           # [64, 128]
        U = matmul(M, V)                  # [64, 128]
        WS = matmul(W, S_prev)            # [64, 128]
    
    sync_to_L2(U, WS)
    
    # ========== Phase 5: Vec pseudo-value ==========
    with Vec():
        V_pseudo = U - WS                 # [64, 128]
    
    sync_to_L2(V_pseudo)
    
    # ========== Phase 6a: Cube 输出 matmul ==========
    with Cube():
        O_inter = matmul(Q_scaled, S_prev)        # [64, 128]
        A_qk_raw = matmul(Q_scaled, K_div.T)      # [64, 64]
    
    sync_to_L2(O_inter, A_qk_raw)
    
    # ========== Phase 6b: Vec Tril mask ==========
    with Vec():
        # Tril 是逐元素操作，Cube 不能做!
        A_qk_tril = tril_mask(A_qk_raw)           # [64, 64]
    
    sync_to_L2(A_qk_tril)
    
    # ========== Phase 6c: Cube intra-chunk matmul ==========
    with Cube():
        O_intra = matmul(A_qk_tril, V_pseudo)     # [64, 128]
    
    sync_to_L2(O_intra)
    
    # ========== Phase 7: Vec 输出融合 ==========
    with Vec():
        O = O_inter + O_intra             # [64, 128]
        
        # 预处理状态更新的衰减
        # 需要 γ^{r→C} = γ^{1→C} / γ^{1→r} = exp(gc[-1] - gc[r])
        decay_to_end = exp(gc[-1:] - gc)  # [64, 128], 每行到 chunk 末尾的衰减
        K_decay = K * decay_to_end        # K[r] * γ^{r→C}
    
    sync_to_L2(K_decay)
    
    # ========== Phase 8: Cube 状态增量 ==========
    with Cube():
        S_delta = matmul(K_decay.T, V_pseudo)  # [128, 128]
    
    sync_to_L2(S_delta)
    
    # ========== Phase 9: Vec 状态融合 ==========
    with Vec():
        # S_new = γ^{1→C} ⊙ S_prev + S_delta
        # γ^{1→C} = exp(gc[-1])
        state_decay = exp(gc[-1])             # [128], chunk 整体衰减
        S_new = S_prev * state_decay.unsqueeze(-1) + S_delta  # [128, 128]
    
    return O, S_new
```

---

## 10. 性能预估

| 阶段 | Cube 计算量 | Vec 计算量 | 主要瓶颈 |
|------|------------|-----------|----------|
| Phase 1 (预处理) | - | 5×64×128 = 40K ops | Vec |
| Phase 2 (A_kk matmul) | 64×128×64 = 524K ops | - | Cube |
| Phase 3 (⊙β + 前向替换) | - | 64×64 + ~4K = 8K ops | Vec |
| Phase 4 (W, U, WS) | 3×64×64×128 = 1.6M ops | - | Cube |
| Phase 5 (U - WS) | - | 64×128 = 8K ops | Vec |
| Phase 6a (O_inter, A_qk) | 2×64×128×128 = 2.1M ops | - | Cube |
| Phase 6b (Tril mask) | - | 64×64 = 4K ops | Vec |
| Phase 6c (O_intra) | 64×64×128 = 524K ops | - | Cube |
| Phase 7 (O 融合) | - | 64×128 = 8K ops | Vec |
| Phase 8 (S_delta) | 128×64×128 = 1M ops | - | Cube |
| Phase 9 (S 融合) | - | 128×128 = 16K ops | Vec |

**总计**: 
- Cube: ~5.7M ops (主要是 matmul)
- Vec: ~84K ops (逐元素操作)
- L2 通信: **11 次 Cube↔Vec 切换** (这是主要开销!)

**瓶颈分析**: 
1. Cube 计算本身很快
2. **L2 通信是真正的瓶颈** — 每次 Cube↔Vec 切换都需要通过 L2

---

## 11. 总结

### 核心原则: Cube 只做 matmul，Vec 做一切逐元素操作

| 操作类型 | 执行位置 | 示例 |
|---------|---------|------|
| 矩阵乘法 A @ B | **Cube** | K @ K^T, M @ V, Q @ S |
| 逐元素乘 A ⊙ B | **Vec** | A_kk ⊙ β, K ⊙ Γ |
| 逐元素加减 | **Vec** | U - WS, O_inter + O_intra |
| 激活函数 | **Vec** | exp(gc), cumsum(g) |
| Mask 操作 | **Vec** | Tril(A_qk), StrictTril(A_kk) |

### 流程特点

1. **11 阶段流水线**: 因为逐元素操作必须在 Vec 中完成，导致 Cube↔Vec 切换增多

2. **L2 通信是瓶颈**: 每次 Cube→Vec→Cube 都需要经过 L2 Buffer

3. **优化方向**:
   - 合并相邻的 Vec 操作，减少 L2 通信
   - 多 Head 并行隐藏通信延迟
   - Chunk 间流水线

4. **L2 Buffer 双缓冲**: Ping-Pong 策略减少等待时间

5. **多 Head 并行**: 16 heads 分配到 16 个 Cube+Vec 组，剩余 4 组做预取