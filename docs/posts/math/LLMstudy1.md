# 为什么我不再「追问」AI，而是选择「编辑提示词」？

## 一个反直觉的发现

大多数人和AI对话时,习惯这样做:

> 我:什么是SFT?  
> AI:SFT是有监督微调...  
> 我:那它怎么训练的?  
> AI:通过损失函数...  
> 我:和对齐有什么区别?  
> AI:对齐是...

看起来很自然,对吧?但我发现了一个更强大的方法——**不要追问,而是回到原点,编辑你的第一个提示词**。

这不仅让我更深刻地理解了知识,更重要的是,**它迫使我思考**。

---

## 我的实验:用4轮编辑搞懂SFT

让我展示完整的思考过程。

### 第一轮:寻找好例子

**我的提示词:**
```
我一直不知道什么是SFT。讲解SFT,我更希望用一个良好的例子作为引入。
```

**AI的回答:**

它给了我一个"书呆子"的比喻:

想象一个人读完了世界上所有的书,很擅长预测下一个单词。你问他"中国的首都是哪里",他可能会说:"中国的首都是北京,北京这个地方风景秀美,有故宫、长城..."

他没错,但你只需要知道答案是"北京"。

SFT(有监督微调)就是通过好的问答示例,教会模型**符合人类期待的回复格式**。

**我的状态:** 有了直觉,但还没真正懂。

---

### 第二轮:加入我的理解

关键来了。我没有继续追问"那具体怎么做呢?",而是**把AI的例子融入我的理解,重新编辑提示词**:

**编辑后的提示词:**
```
我一直不知道什么是SFT。讲解SFT,我更希望用一个良好的例子作为引入。
比如说用书呆子的例子吧。一个书呆子已经了解所有的概率预测了,但是
这时候说话的方式也不符合人类的预期。所以你需要通过某种问答的格式
教会这个书呆子如何用符合人类理解的方式进行回答,这就是SFT。通常
通过几百万个问答配对来学习。

但我还有的疑问就是这是如何完成学习的呢?难道也是反向传播?
```

看到了吗?我在编辑时,**被迫整理了上一轮学到的内容**。这个过程让我意识到:AI一开始没提损失函数,可能认为我是业余爱好者(确实是)。

但当我自己思考"它怎么训练"时,我就会追问技术细节。

**AI的新回答:**

对!也是反向传播,但**损失函数不同**:
- 预训练:预测下一个词的概率误差
- SFT:生成的回答与人类标准答案的差距

**我的状态:** 技术原理清楚了,但应用场景还模糊。

---

### 第三轮:拓展边界

我又一次编辑提示词,加入新理解:

**再次编辑的提示词:**
```
我一直不知道什么是SFT。讲解SFT,我更希望用一个良好的例子作为引入。
比如说用书呆子的例子吧。一个书呆子已经了解所有的概率预测了,但是
这时候说话的方式也不符合人类的预期。所以你需要通过某种问答的格式
教会这个书呆子如何用符合人类理解的方式进行回答,这就是SFT。通常
通过几百万个问答配对来学习。

这个完成学习是通过人类的问题输入进去,让其输出回答,然后判断和人类
给出回答之间的差距作为loss,让其慢慢符合人类的回答。

但所有的SFT都是这样的吗?我经常听到SFT,不知道在其他场景还有没有
SFT。SFT还有什么其他作用。
```

**AI的回答:**

SFT的应用远不止问答:
- **领域专精:** 让模型成为专业医生、律师
- **能力注入:** 教会模型如何思考(CoT)、如何调用工具
- **行为塑造:** 让模型诚实说"我不知道",而非胡编乱造

**我的状态:** 全景图出现了,但还有一个根本问题...

---

### 第四轮:辨析概念

最后一次编辑,我加入了最困惑我的问题:

**最终版提示词:**
```
我一直不知道什么是SFT。讲解SFT,我更希望用一个良好的例子作为引入。
比如说用书呆子的例子吧。一个书呆子已经了解所有的概率预测了,但是
这时候说话的方式也不符合人类的预期。所以你需要通过某种问答的格式
教会这个书呆子如何用符合人类理解的方式进行回答,这就是SFT。通常
通过几百万个问答配对来学习。

这个完成学习是通过人类的问题输入进去,让其输出回答,然后判断和人类
给出回答之间的差距作为loss,让其慢慢符合人类的回答。SFT可以比如
教会模型如何调用工具、如何思考。

但是问题是,这些和后面的对齐有什么区别?也就是第三阶段。
```

**AI的回答:**

关键区别:
- **SFT:** 教会模型"能用"(格式正确、功能可用)
- **对齐(RLHF):** 让模型"好用"(回答质量、价值观)

SFT之后模型已经可以对话,但对齐才决定生成内容的优劣。

**我的状态:** 真正理解了。

---

## 为什么「编辑」比「追问」更强大?

回顾整个过程,我意识到三个关键差异:

### 1. 编辑=主动建构,追问=被动接收

**追问模式:**
```
你:A是什么?
AI:A是...
你:那B呢?  ← 你只是在等待投喂
AI:B是...
```

**编辑模式:**
```
你:A是什么?
AI:A是...
你:(整理理解)A是...对吧?那我的疑问是B  ← 你必须先消化
AI:对,B是...
```

编辑时,你**被迫用自己的话重新组织知识**,这本身就是深度学习的过程。

### 2. 编辑暴露你的思维盲区

当我写下"通过几百万个问答配对来学习"时,我突然意识到:"等等,它怎么学习?也是反向传播吗?"

如果只是追问,我可能会问"SFT的原理是什么"——这个问题太宽泛,得到的答案也会很宽泛。

但编辑让我**精确定位了我不懂的部分**。

### 3. 编辑产生完整的知识地图

四轮编辑后,我的最终提示词本身就是一份**结构化笔记**:

```
SFT是什么?  → 书呆子比喻
怎么实现?   → 损失函数+反向传播  
有什么用?   → 问答、专精、能力、行为
和对齐区别? → 能用 vs 好用
```

如果是追问,我的聊天记录会是一团乱麻。

---

## 方法论:如何编辑提示词

基于这次实验,我总结了一个流程:

### Step 1: 初始提问(越具体越好)
❌ "什么是SFT?"  
✅ "讲解SFT,我希望用一个好例子作为引入"

### Step 2: 读完回答后,不要立即追问
暂停5秒,问自己:
- 我用自己的话能复述吗?
- 我有哪里没懂?
- 我能想到什么新问题?

### Step 3: 编辑原提示词,加入你的理解
格式模板:
```
[原问题]
[你用自己话复述的理解]
但我的疑问是:[精确的新问题]
```

### Step 4: 重复2-3次,直到没有新问题

关键指标:**你能完整、准确地向别人讲解这个概念**。

---

## 你可以试试这个挑战

选一个你似懂非懂的概念(比如"Transformer""强化学习""区块链"),然后:

**核心只有一条规则:每次读完AI的回答,尝试向一个朋友复述。**

当你复述时:
- 卡在哪里,就编辑提示词问哪里
- 想到什么疑问,就编辑提示词加进去
- 发现理解有误,就编辑提示词纠正

**没有固定的轮次,没有标准的顺序**——你的思维在哪里被"愣住",你的下一个问题就在哪里。

如果你坚持编辑而非追问,**你会发现自己在教AI如何教你**。

---

## 最后的思考

这个方法的本质,其实是**让AI成为你的思考脚手架**,而非知识贩卖机。

追问模式下,你在消费AI的输出。  
编辑模式下,你在和AI共同建构知识。

就像SFT教会模型"符合人类预期的回答方式"一样,编辑提示词也在教会你自己:**如何提出更好的问题**。

而提出好问题,才是学习的终极能力。

---

**你呢?你是追问派还是编辑派?欢迎在评论区分享你的AI学习方法。**

---

*P.S. 如果这篇文章对你有启发,不妨试着用「编辑提示词」的方法,向AI提问"如何更好地使用这个方法"——然后把你的最终提示词发给我,我很好奇你会得到什么新发现。*